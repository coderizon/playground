import { runInference } from './modelBridge.js';
import { sessionStore, INFERENCE_STATUS } from '../../app/store/sessionStore.js';

let inferenceLoopHandle = null;

export function startLiveInference(videoEl) {
  if (!videoEl) {
    throw new Error('Kein Videoelement fÃ¼r Inferenz vorhanden.');
  }
  stopLiveInference();
  sessionStore.setInferenceStatus(INFERENCE_STATUS.RUNNING, {
    lastPrediction: null,
    error: null,
  });

  const loop = async () => {
    if (sessionStore.getState().inference.status !== INFERENCE_STATUS.RUNNING) {
      stopLiveInference();
      return;
    }
    try {
      await runInference(videoEl);
    } catch (error) {
      console.error(error);
      sessionStore.setInferenceStatus(INFERENCE_STATUS.ERROR, { error: error.message });
      stopLiveInference();
      return;
    }
    inferenceLoopHandle = window.requestAnimationFrame(loop);
  };

  inferenceLoopHandle = window.requestAnimationFrame(loop);
}

export function stopLiveInference() {
  if (inferenceLoopHandle) {
    window.cancelAnimationFrame(inferenceLoopHandle);
    inferenceLoopHandle = null;
  }
  const current = sessionStore.getState();
  if (current.inference.status === INFERENCE_STATUS.RUNNING) {
    sessionStore.setInferenceStatus(INFERENCE_STATUS.STOPPED, { lastPrediction: null });
  }
}
